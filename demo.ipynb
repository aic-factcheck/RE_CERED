{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P19 místo narození\n",
      "P463 člen (čeho)\n",
      "P264 hudební vydavatelství\n"
     ]
    }
   ],
   "source": [
    "from RE_model_base import RelationExtractionModel\n",
    "from RE_model_base import consts\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "labels_path = \"CERED2_LABELS\"\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "LABELS = []\n",
    "with open(labels_path, \"r\") as f:\n",
    "    LABELS = json.load(f)\n",
    "    LABELS = [x[0] + ' ' + x[1] for x in LABELS]\n",
    "    for i, label in enumerate(LABELS):\n",
    "        id2label[i] = label\n",
    "        label2id[label] = i\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stulcrad/XLM-RoBERTa-2\", add_prefix_space=True)\n",
    "model = RelationExtractionModel.from_pretrained(\"stulcrad/XLM-RoBERTa-2\", tokenizer=tokenizer,\n",
    "                                                id2label=id2label, label2id=label2id,\n",
    "                                                num_labels=len(LABELS))\n",
    "\n",
    "sentence1 = \"[E1] Jan [/E1] se narodil v [E2] Praze [/E2] .\"\n",
    "sentence2 = \"Vydáno bylo 17 . února roku 2017 společností [E2] Domino Records [/E2] , téměř přesně rok po vydání desky [E1] Painting With [/E1] . \"\n",
    "sentence_example = \"[E1] Jan Máchal [/E1] ( 9. února 1864, Třebíč [UNK] 15. října 1924, Třebíč ) byl český pedagog, činovník [E2] Sokola [/E2] . \"\n",
    "special_token_dict = {\n",
    "    '[E1]':consts.E1_START_TOKEN, '[/E1]':consts.E1_END_TOKEN,\n",
    "    '[E2]':consts.E2_START_TOKEN, '[/E2]':consts.E2_END_TOKEN\n",
    "}\n",
    "\n",
    "marked = [token if token not in special_token_dict else special_token_dict[token] for token in sentence1.split(' ')]\n",
    "marked2 = [token if token not in special_token_dict else special_token_dict[token] for token in sentence2.split(' ')]\n",
    "marked_example = [token if token not in special_token_dict else special_token_dict[token] for token in sentence_example.split(' ')]\n",
    "# print(marked)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "marked_sentence = \"\"\n",
    "marked_sentence_example = \"\"\n",
    "marked_sentence2 = \"\"\n",
    "first = True\n",
    "for token in marked:\n",
    "    if first:\n",
    "        first = False\n",
    "        marked_sentence += token\n",
    "    else:\n",
    "        marked_sentence += \" \" + token\n",
    "first = True\n",
    "for token in marked_example:\n",
    "    if first:\n",
    "        first = False\n",
    "        marked_sentence_example += token\n",
    "    else:\n",
    "        marked_sentence_example += \" \" + token\n",
    "first = True\n",
    "for token in marked2:\n",
    "    if first:\n",
    "        first = False\n",
    "        marked_sentence2 += token\n",
    "    else:\n",
    "        marked_sentence2 += \" \" + token\n",
    "\n",
    "\n",
    "inputs = tokenizer(marked_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "inputs_example = tokenizer(marked_sentence_example, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "inputs2 = tokenizer(marked_sentence2, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "inputs.to(device)\n",
    "inputs_example.to(device)\n",
    "inputs2.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    outputs_example = model(**inputs_example)\n",
    "    outputs2 = model(**inputs2)\n",
    "    logits = outputs[\"logits\"]\n",
    "    logits_example = outputs_example[\"logits\"]\n",
    "    logits2 = outputs2[\"logits\"]\n",
    "\n",
    "pred_labels = logits.argmax().item()\n",
    "pred_labels_example = logits_example.argmax().item()\n",
    "pred_labels2 = logits2.argmax().item()\n",
    "print(id2label[pred_labels])\n",
    "print(id2label[pred_labels_example])\n",
    "print(id2label[pred_labels2])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
